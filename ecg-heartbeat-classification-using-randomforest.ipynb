{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37484,"sourceType":"datasetVersion","datasetId":29414}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Definition\n### Objective: Classify ECG signals into normal and abnormal categories.\n\n# Datasets:\n\n### MIT-BIH: For arrhythmia classification (5 classes: N, S, V, F, Q).\n\n### PTBDB: For myocardial infarction classification (2 classes: normal, abnormal).\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import StandardScaler\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:44.187978Z","iopub.execute_input":"2025-03-09T18:00:44.188348Z","iopub.status.idle":"2025-03-09T18:00:44.196603Z","shell.execute_reply.started":"2025-03-09T18:00:44.188321Z","shell.execute_reply":"2025-03-09T18:00:44.195548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ptbdb_abnormal_df = pd.read_csv(\"/kaggle/input/heartbeat/ptbdb_abnormal.csv\", header=None)\nptbdb_normal_df = pd.read_csv(\"/kaggle/input/heartbeat/ptbdb_normal.csv\", header=None)\n\nmitbih_train_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_train.csv\", header=None)\nmitbih_test_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_test.csv\", header=None)\n\n#mitbih_train_df.head()\n#mitbih_test_df.head()\n#ptbdb_abnormal_df.head()\n#ptbdb_normal_df.head()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:44.198196Z","iopub.execute_input":"2025-03-09T18:00:44.198563Z","iopub.status.idle":"2025-03-09T18:00:50.930367Z","shell.execute_reply.started":"2025-03-09T18:00:44.198537Z","shell.execute_reply":"2025-03-09T18:00:50.929200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for null values in MIT-BIH datasets\nprint(\"MIT-BIH Train - Null values:\\n\", mitbih_train_df.isnull().sum())\nprint(\"MIT-BIH Test - Null values:\\n\", mitbih_test_df.isnull().sum())\n\n# Check for null values in PTBDB datasets\nprint(\"PTBDB Abnormal - Null values:\\n\", ptbdb_abnormal_df.isnull().sum())\nprint(\"PTBDB Normal - Null values:\\n\", ptbdb_normal_df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:50.932092Z","iopub.execute_input":"2025-03-09T18:00:50.932540Z","iopub.status.idle":"2025-03-09T18:00:51.025571Z","shell.execute_reply.started":"2025-03-09T18:00:50.932495Z","shell.execute_reply":"2025-03-09T18:00:51.024539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for duplicates in MIT-BIH datasets\nprint(\"MIT-BIH Train - Duplicates:\", mitbih_train_df.duplicated().sum())\nprint(\"MIT-BIH Test - Duplicates:\", mitbih_test_df.duplicated().sum())\n\n# Check for duplicates in PTBDB datasets\nprint(\"PTBDB Abnormal - Duplicates:\", ptbdb_abnormal_df.duplicated().sum())\nprint(\"PTBDB Normal - Duplicates:\", ptbdb_normal_df.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:51.027076Z","iopub.execute_input":"2025-03-09T18:00:51.027368Z","iopub.status.idle":"2025-03-09T18:00:51.924643Z","shell.execute_reply.started":"2025-03-09T18:00:51.027342Z","shell.execute_reply":"2025-03-09T18:00:51.923391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"MIT-BIH Train Shape:\", mitbih_train_df.shape)\nprint(\"MIT-BIH Test Shape:\", mitbih_test_df.shape)\nprint(\"PTBDB Abnormal Shape:\", ptbdb_abnormal_df.shape)\nprint(\"PTBDB Normal Shape:\", ptbdb_normal_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:51.926196Z","iopub.execute_input":"2025-03-09T18:00:51.926496Z","iopub.status.idle":"2025-03-09T18:00:51.933772Z","shell.execute_reply.started":"2025-03-09T18:00:51.926470Z","shell.execute_reply":"2025-03-09T18:00:51.932554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MIT-BIH datasets\nX_mitbih_train = mitbih_train_df.iloc[:, :-1].values  # Features\ny_mitbih_train = mitbih_train_df.iloc[:, -1].values  # Labels\n\nX_mitbih_test = mitbih_test_df.iloc[:, :-1].values  # Features\ny_mitbih_test = mitbih_test_df.iloc[:, -1].values  # Labels\n\n# PTBDB datasets\nX_ptbdb_abnormal = ptbdb_abnormal_df.iloc[:, :-1].values  # Features\ny_ptbdb_abnormal = ptbdb_abnormal_df.iloc[:, -1].values  # Labels\n\nX_ptbdb_normal = ptbdb_normal_df.iloc[:, :-1].values  # Features\ny_ptbdb_normal = ptbdb_normal_df.iloc[:, -1].values  # Labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:51.935228Z","iopub.execute_input":"2025-03-09T18:00:51.935613Z","iopub.status.idle":"2025-03-09T18:00:51.950674Z","shell.execute_reply.started":"2025-03-09T18:00:51.935569Z","shell.execute_reply":"2025-03-09T18:00:51.949531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine PTBDB datasets\nX_ptbdb = np.vstack((X_ptbdb_abnormal, X_ptbdb_normal))\ny_ptbdb = np.hstack((y_ptbdb_abnormal, y_ptbdb_normal))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:51.951748Z","iopub.execute_input":"2025-03-09T18:00:51.952043Z","iopub.status.idle":"2025-03-09T18:00:51.973340Z","shell.execute_reply.started":"2025-03-09T18:00:51.952020Z","shell.execute_reply":"2025-03-09T18:00:51.972300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Initialize Random Forest\nrf_mitbih = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_mitbih.fit(X_mitbih_train, y_mitbih_train)\n\n# Evaluate on test data\ny_mitbih_pred = rf_mitbih.predict(X_mitbih_test)\n\n# Print results\nprint(\"MIT-BIH Test Accuracy:\", accuracy_score(y_mitbih_test, y_mitbih_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_mitbih_test, y_mitbih_pred))\nprint(\"Classification Report:\\n\", classification_report(y_mitbih_test, y_mitbih_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:00:51.974729Z","iopub.execute_input":"2025-03-09T18:00:51.975047Z","iopub.status.idle":"2025-03-09T18:03:32.476560Z","shell.execute_reply.started":"2025-03-09T18:00:51.975002Z","shell.execute_reply":"2025-03-09T18:03:32.475520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize Random Forest\nrf_ptbdb = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_ptbdb.fit(X_ptbdb, y_ptbdb)\n\n# Evaluate on test data (if you have a separate test set)\n# Otherwise, evaluate on the training data\ny_ptbdb_pred = rf_ptbdb.predict(X_ptbdb)\n\n# Print results\nprint(\"PTBDB Test Accuracy:\", accuracy_score(y_ptbdb, y_ptbdb_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_ptbdb, y_ptbdb_pred))\nprint(\"Classification Report:\\n\", classification_report(y_ptbdb, y_ptbdb_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:04:27.085256Z","iopub.execute_input":"2025-03-09T18:04:27.085651Z","iopub.status.idle":"2025-03-09T18:04:39.179222Z","shell.execute_reply.started":"2025-03-09T18:04:27.085621Z","shell.execute_reply":"2025-03-09T18:04:39.178202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get feature importances\nimportances_mitbih = rf_mitbih.feature_importances_\nimportances_ptbdb = rf_ptbdb.feature_importances_\n\n# Plot feature importances\nimport matplotlib.pyplot as plt\n\n# MIT-BIH feature importance\nplt.figure(figsize=(10, 6))\nplt.bar(range(X_mitbih_train.shape[1]), importances_mitbih)\nplt.title(\"MIT-BIH Feature Importance\")\nplt.xlabel(\"Feature Index\")\nplt.ylabel(\"Importance\")\nplt.show()\n\n# PTBDB feature importance\nplt.figure(figsize=(10, 6))\nplt.bar(range(X_ptbdb.shape[1]), importances_ptbdb)\nplt.title(\"PTBDB Feature Importance\")\nplt.xlabel(\"Feature Index\")\nplt.ylabel(\"Importance\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:05:20.443035Z","iopub.execute_input":"2025-03-09T18:05:20.443373Z","iopub.status.idle":"2025-03-09T18:05:21.748650Z","shell.execute_reply.started":"2025-03-09T18:05:20.443345Z","shell.execute_reply":"2025-03-09T18:05:21.747692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n# Save MIT-BIH model\njoblib.dump(rf_mitbih, \"rf_mitbih_model.pkl\")\n\n# Save PTBDB model\njoblib.dump(rf_ptbdb, \"rf_ptbdb_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T18:17:27.948516Z","iopub.execute_input":"2025-03-09T18:17:27.948909Z","iopub.status.idle":"2025-03-09T18:17:28.096725Z","shell.execute_reply.started":"2025-03-09T18:17:27.948877Z","shell.execute_reply":"2025-03-09T18:17:28.095916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\nThis project successfully applied Random Forest classifiers to the task of ECG heartbeat classification using two datasets: MIT-BIH Arrhythmia Dataset and PTB Diagnostic ECG Database. The models demonstrated excellent performance, showcasing the strengths of Random Forests in handling high-dimensional data and class imbalance.\n\n# Key Achievements\n1. MIT-BIH Arrhythmia Dataset\nAccuracy: 97.47%\n\n# Confusion Matrix:\n\nThe model performed exceptionally well on the majority class (Class 0: Normal Heartbeat), with 18,104 correct predictions and only 14 misclassifications.\n\nFor minority classes (e.g., Class 1: Supraventricular Premature Beat and Class 3: Fusion of Ventricular and Normal Beat), the model struggled slightly but still achieved reasonable performance.\n\n# Classification Report:\n\nHigh precision, recall, and F1-score for most classes, indicating a robust model.\n\nThe model achieved a weighted F1-score of 0.97, demonstrating its ability to handle imbalanced data effectively.\n\n2. PTB Diagnostic ECG Database\nAccuracy: 100%\n\n# Confusion Matrix:\n\nThe model achieved perfect classification for both normal and abnormal ECG signals.\n\nAll 4,046 normal samples and 10,506 abnormal samples were correctly classified.\n\nClassification Report:\n\nPrecision, recall, and F1-score were all 1.00 for both classes, indicating flawless performance.\n\n# Strengths of Random Forest\nHandling High-Dimensional Data:\n\nRandom Forests effectively handled the 187-dimensional ECG signals, demonstrating their ability to work with high-dimensional data.\n\n# Robustness to Class Imbalance:\n\nDespite the imbalanced nature of the datasets (e.g., MIT-BIH), Random Forests performed well, especially when combined with techniques like class weighting.\n\n# Interpretability:\n\nRandom Forests provide feature importance scores, which help in understanding which ECG signal features contributed most to the classification.\n\n# Scalability:\n\nThe models trained quickly and scaled well to the size of the datasets, making them suitable for real-time applications.\n\n# Capacities of the Models\n### Real-Time Classification:\n\nThe models can be deployed in real-time systems (e.g., wearable devices, hospital monitoring systems) to classify ECG signals instantly.\n\n### Generalization:\n\nThe models demonstrated strong generalization capabilities, especially on the PTBDB dataset, where they achieved 100% accuracy.\n\n### Flexibility:\n\nThe models can be adapted to other ECG datasets or similar time-series classification tasks with minimal changes.\n\n# Limitations and Future Work\n### Class Imbalance:\n\nWhile Random Forests performed well, minority classes (e.g., Class 1 and Class 3 in MIT-BIH) could benefit from further improvement using techniques like oversampling or ensemble methods.\n\n### Feature Engineering:\n\nAdditional feature engineering (e.g., extracting frequency-domain features) could further enhance model performance.\n\n### Model Interpretability:\n\nWhile feature importance scores provide some interpretability, more advanced techniques (e.g., SHAP values) could be used to better understand the model's decision-making process.\n\n# Deployment Challenges:\n\nDeploying the models in real-world scenarios (e.g., edge devices) may require optimization for memory and computational efficiency.\n\n# Final Thoughts\nThe Random Forest models demonstrated excellent performance on both the MIT-BIH and PTBDB datasets, achieving high accuracy and robust classification capabilities. Their ability to handle high-dimensional data, class imbalance, and provide interpretable results makes them a strong choice for ECG heartbeat classification tasks.\n\nBy addressing the limitations (e.g., class imbalance, feature engineering) and leveraging the strengths of Random Forests, this project lays a solid foundation for building real-time ECG classification systems that can assist healthcare professionals in diagnosing arrhythmias and other heart conditions.","metadata":{}}]}